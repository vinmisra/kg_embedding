from collections import OrderedDict
import sys

def get_hypers(exp):
    hypers = OrderedDict()
    if exp == 'H1':
        hypers['EXP'] = 'H1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = False
    elif exp=='H2':
        hypers['EXP'] = 'H2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H3':
        hypers['EXP'] = 'H3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H4':
        hypers['EXP'] = 'H4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H5':
        hypers['EXP'] = 'H5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H6':
        hypers['EXP'] = 'H6' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H7':
        hypers['EXP'] = 'H7' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H8':
        hypers['EXP'] = 'H8' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H9':
        hypers['EXP'] = 'H9' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H10':
        hypers['EXP'] = 'H10' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H11':
        hypers['EXP'] = 'H11' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 25 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H12':
        hypers['EXP'] = 'H12' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H13':
        hypers['EXP'] = 'H13' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 35 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H14':
        hypers['EXP'] = 'H14' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H15':
        hypers['EXP'] = 'H13' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 45 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H16':
        hypers['EXP'] = 'H16' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H17':
        hypers['EXP'] = 'H17' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H18':
        hypers['EXP'] = 'H18' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H19':
        hypers['EXP'] = 'H19' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H20':
        hypers['EXP'] = 'H20' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H21':
        hypers['EXP'] = 'H21' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H22':
        hypers['EXP'] = 'H22' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H23':
        hypers['EXP'] = 'H23' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 45 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H24':
        hypers['EXP'] = 'H24' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H25':
        hypers['EXP'] = 'H25' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 80 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H17.1':
        hypers['EXP'] = 'H17.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 80 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H17.2':
        hypers['EXP'] = 'H17.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H17.3':
        hypers['EXP'] = 'H17.3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 150 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H17.4':
        hypers['EXP'] = 'H17.4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 200 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H19.1':
        hypers['EXP'] = 'H19.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 90 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H19.2':
        hypers['EXP'] = 'H19.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 120 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H19.3':
        hypers['EXP'] = 'H19.3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 150 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H19.4':
        hypers['EXP'] = 'H19.4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 200 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H26':
        hypers['EXP'] = 'H26' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H27':
        hypers['EXP'] = 'H27' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 150 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H28':
        hypers['EXP'] = 'H28' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 200 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H29':
        hypers['EXP'] = 'H29' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 300 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
    elif exp=='H30':
        hypers['EXP'] = 'H30' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 10 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = True
    elif exp=='H31':
        hypers['EXP'] = 'H31' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H32':
        hypers['EXP'] = 'H32' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H33':
        hypers['EXP'] = 'H33' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H34':
        hypers['EXP'] = 'H34' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H35':
        hypers['EXP'] = 'H35' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30 #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H36':
        hypers['EXP'] = 'H36' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H37':
        hypers['EXP'] = 'H37' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H38':
        hypers['EXP'] = 'H38' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H39':
        hypers['EXP'] = 'H39' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H40':
        hypers['EXP'] = 'H40' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H41':
        hypers['EXP'] = 'H41' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 35    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H42':
        hypers['EXP'] = 'H42' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H43':
        hypers['EXP'] = 'H43' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H44':
        hypers['EXP'] = 'H44' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 3    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='H45':
        hypers['EXP'] = 'H45' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 7    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I1':
        hypers['EXP'] = 'I1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I2':
        hypers['EXP'] = 'I2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I3':
        hypers['EXP'] = 'I3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I4':
        hypers['EXP'] = 'I4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I5':
        hypers['EXP'] = 'I5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I6':
        hypers['EXP'] = 'I6' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I6.1':
        hypers['EXP'] = 'I6.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I6.2':
        hypers['EXP'] = 'I6.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I7':
        hypers['EXP'] = 'I7' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I8':
        hypers['EXP'] = 'I8' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9':
        hypers['EXP'] = 'I9' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9.1':
        hypers['EXP'] = 'I9.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9.2':
        hypers['EXP'] = 'I9.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9.3':
        hypers['EXP'] = 'I9.3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9.4':
        hypers['EXP'] = 'I9.4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I9.5':
        hypers['EXP'] = 'I9.5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I10':
        hypers['EXP'] = 'I10' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I11':
        hypers['EXP'] = 'I11' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12':
        hypers['EXP'] = 'I12' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12.1':
        hypers['EXP'] = 'I12.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12.2':
        hypers['EXP'] = 'I12.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12.3':
        hypers['EXP'] = 'I12.3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12.4':
        hypers['EXP'] = 'I12.4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I12.5':
        hypers['EXP'] = 'I12.5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I13':
        hypers['EXP'] = 'I13' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I14':
        hypers['EXP'] = 'I14' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15':
        hypers['EXP'] = 'I15' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15.1':
        hypers['EXP'] = 'I15.1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 4    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15.2':
        hypers['EXP'] = 'I15.2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15.3':
        hypers['EXP'] = 'I15.3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15.4':
        hypers['EXP'] = 'I15.4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I15.5':
        hypers['EXP'] = 'I15.5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 75   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I16':
        hypers['EXP'] = 'I16' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I17':
        hypers['EXP'] = 'I17' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I18':
        hypers['EXP'] = 'I18' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I19':
        hypers['EXP'] = 'I19' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I20':
        hypers['EXP'] = 'I20' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I21':
        hypers['EXP'] = 'I21' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I22':
        hypers['EXP'] = 'I22' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I23':
        hypers['EXP'] = 'I23' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I24':
        hypers['EXP'] = 'I24' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I25':
        hypers['EXP'] = 'I25' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I26':
        hypers['EXP'] = 'I26' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I27':
        hypers['EXP'] = 'I27' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I28':
        hypers['EXP'] = 'I28' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I29':
        hypers['EXP'] = 'I29' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I30':
        hypers['EXP'] = 'I30' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I31':
        hypers['EXP'] = 'I31' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I32':
        hypers['EXP'] = 'I32' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 7 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I33':
        hypers['EXP'] = 'I33' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 7 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='I34':
        hypers['EXP'] = 'I34' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 7 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA1':
        hypers['EXP'] = 'AA1' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA2':
        hypers['EXP'] = 'AA2' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA3':
        hypers['EXP'] = 'AA3' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA4':
        hypers['EXP'] = 'AA4' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA5':
        hypers['EXP'] = 'AA5' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA6':
        hypers['EXP'] = 'AA6' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA7':
        hypers['EXP'] = 'AA7' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA8':
        hypers['EXP'] = 'AA8' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA9':
        hypers['EXP'] = 'AA9' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA10':
        hypers['EXP'] = 'AA10' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA11':
        hypers['EXP'] = 'AA11' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA12':
        hypers['EXP'] = 'AA12' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 20    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA13':
        hypers['EXP'] = 'AA13' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='AA14':
        hypers['EXP'] = 'AA14' #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DB_V'] = 241
        hypers['MIN_MENTIONS'] = 2
        hypers['MIN_ENTITIES'] = 2
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 1000000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 1 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.001 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S10b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S16':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S11debug':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=200
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S17':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 100    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S18':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 90    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S19':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 80    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S20':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S21':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S22':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.9
    elif exp=='S23':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.9
    elif exp=='S24':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.9
    elif exp=='S25':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 60    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.9
    elif exp=='S26':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 70    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.9
    elif exp=='S27':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.5
    elif exp=='S28':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.6
    elif exp=='S29':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.7
    elif exp=='S30':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.8
    elif exp=='S31':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'RMSPROP' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=400
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['TRAIN_PARAM'] = 0.95
    elif exp=='S32':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S33':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S34':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S35':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S36':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S37':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S38':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S39':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S40':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S41':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S42':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S43':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S44':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S45':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 40    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='S46':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = -5 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 200   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGc4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGc5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGc6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGc7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DGb10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 200   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG13b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 3    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG13c':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG14b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['DATA_SYMMETRY'] = True
    elif exp=='DG14c':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_NCE_CORRECTED'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-1b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-1c':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = False
    elif exp=='DG14-1d':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = False
    elif exp=='DG14-2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 1
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = False
    elif exp=='DG14-2b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 1
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-2c':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 1
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 1
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-4a':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_NCE_CORRECTED'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-4a2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -0.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
        hypers['NCE_CORRECTION'] = True
        hypers['NCE_B_CORRECTION'] = True
    elif exp=='DG14-4b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = False
    elif exp=='DG14-4c':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -11.81587598
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = True
    elif exp=='DG14-4d':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = False
        hypers['DIRECTED_PREDICTION'] = False
        hypers['NCE_CORRECTION'] = False
    elif exp=='DG14-4e':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIGRAM'
        hypers['UNIGRAM_POWER'] = 0.75
        hypers['DATA_SYMMETRY'] = True
        hypers['DIRECTED_PREDICTION'] = True
        hypers['NCE_CORRECTION'] = False
    elif exp=='DG15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG16':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG161':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG162':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG163':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG164':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG165':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG166':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 35   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG17':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 5   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG18':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG19':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 15   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG20':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 20   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG21':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG22':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 50   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG23':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG24':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 200   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG25':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG26':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 30    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG27':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 15    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG28':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG29':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG30':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG30b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG31':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG32':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG33':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='DG34':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 100   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 50    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'REAL_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = False
        hypers['TRANSFORM_SCALING'] = False
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='NB15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='2NB15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    elif exp=='3NB1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='3NB15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='2NB2b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = False
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='4NB1':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB2':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB2b':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 10    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
    elif exp=='4NB3':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
    elif exp=='4NB4':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'KG' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB5':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2   #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB6':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB7':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB8':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 1    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB9':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB10':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 100000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = .2    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB11':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB12':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 10   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='3NB13':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'WORDNET' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB14':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = 3 #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    elif exp=='4NB15':
        hypers['EXP'] = exp #exp identifier
        hypers['DATASET'] = 'SLASHDOT' #KG, FREEBASE, WORDNET
        hypers['DIM'] = 25   #embedding dimensionality
        hypers['N_ENTITIES'] = None 
        hypers['BATCH_SIZE'] = 10000 #batch size for training 
        hypers['N_SAMPLES'] = 1 #number of samples to take while computing sampled loss. relevant for reported performance, but not for gradients.
        hypers['OBJECTIVE_SAMPLES'] = None #None means revert to expectation. 1 means 1 and then 2 "half weighted" tail samples.
        hypers['VALIDATION_HOLDOUT'] = 0.05 #fraction of edges to hold out for validation purposes 0#
        hypers['LR'] = 5    #learning rate for training
        hypers['TRAINING'] = 'ADAGRAD' #either 'ADAGRAD' or 'SGD'
        hypers['EMBEDDING_TYPE'] = 'BIT_INTERNALB'
        hypers['PARAMETERIZATION'] = 'SIGMOID'
        hypers['NEIGHBORHOOD'] = True
        hypers['TRANSFORM_SCALING'] = True
        hypers['N_EPOCHS']=1000
        hypers['INIT_A'] = 1
        hypers['INIT_B'] = -.5
        hypers['INIT_A_N'] = 0 
        hypers['SEED'] = 2052016
        hypers['SHUFFLE_DATA'] = True
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
        hypers['NEIGHBORHOOD_MEAN'] = True
        hypers['GRAPH_SYMMETRY'] = False
        hypers['NEIGHBORHOOD_WEIGHTING'] = True
    else:
        print "experiment label not found! Aborting."
        sys.exit(0)
    if 'QUANTILE_FLOOR_AND_CEILING' not in hypers:
        hypers['QUANTILE_FLOOR_AND_CEILING'] = False
    if 'GRAPH_SYMMETRY' not in hypers:
        hypers['GRAPH_SYMMETRY'] = True
    if 'NEIGHBORHOOD_MEAN' not in hypers:
        hypers['NEIGHBORHOOD_MEAN'] = False
    if 'NEIGHBORHOOD_WEIGHTING' not in hypers:
        hypers['NEIGHBORHOOD_WEIGHTING'] = False
    if 'NEGATIVE_SAMPLING_TYPE' not in hypers:
        hypers['NEGATIVE_SAMPLING_TYPE'] = 'UNIFORM'
    if 'UNIGRAM_POWER' not in hypers:
        hypers['UNIGRAM_POWER'] = 0
    if 'DATA_SYMMETRY' not in hypers:
        hypers['DATA_SYMMETRY']= False
    if 'DIRECTED_PREDICTION' not in hypers:
        hypers['DIRECTED_PREDICTION']= False
    if 'NCE_CORRECTION' not in hypers:
        if 'NEGATIVE_SAMPLING_TYPE' in hypers and hypers['NEGATIVE_SAMPLING_TYPE'] == 'UNIGRAM':
            hypers['NCE_CORRECTION'] = True
    if 'NCE_B_CORRECTION' not in hypers:
        hypers['NCE_B_CORRECTION'] = False
    return hypers