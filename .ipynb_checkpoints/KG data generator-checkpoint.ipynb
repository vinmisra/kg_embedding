{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MACHINE CONSTANTS\n",
    "dir_db2= '/home/db2inst1/vinith/'\n",
    "#dir_local= '/ceph/vinith/kg/embedding/' #piazza-vm03\n",
    "dir_local = '/home/vmisra/data/kg/' #piazza-watson03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates SQL which generates positive training samples and negative training material.\n",
    "\n",
    "Then save positive and negative samples (generated) to pickled numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_db2= '/home/db2inst1/vinith/'\n",
    "dir_local= '/ceph/vinith/kg/embedding/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "from collections import OrderedDict\n",
    "#from ggplot import *\n",
    "import re\n",
    "import math,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_distinct__v233_minmentions2_style_derived_uniques\n"
     ]
    }
   ],
   "source": [
    "#constants for parametrizing the positive/negative sample generation\n",
    "MIN_MENTIONS=2\n",
    "DB_V = '233'\n",
    "SAMPLE_STYLE = '_derived_uniques'\n",
    "DISTINCT='_distinct_' #change to '' if working with older reltype-other entitystats dumps.\n",
    "\n",
    "standard_suffix = '%(distinct)s_v%(db_v)s_minmentions%(min_mentions)i_style%(style)s' % {'distinct':DISTINCT,'db_v':DB_V, 'min_mentions':MIN_MENTIONS, 'style':SAMPLE_STYLE}\n",
    "print standard_suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Dump relations from DB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "connect to KG_R233;\n",
      "export to /home/db2inst1/vinith/dump_v233_minmentions2.del of del\n",
      "SELECT * FROM\n",
      "(Select \n",
      "    \"subject/instanceName_up\",\n",
      "    \"subject/typeType\",\n",
      "    \"object/instanceName_up\",\n",
      "    \"object/typeType\",\n",
      "    \"relCanonicalName\",\n",
      "    SUM(\"mAB_doc\") as \"mAB\",\n",
      "    count(*) as \"n_docs\"\n",
      "from (\n",
      "     Select\n",
      "        \"subject/instanceName_up\",\n",
      "        \"subject/typeType\",\n",
      "        \"object/instanceName_up\",\n",
      "        \"object/typeType\",\n",
      "        \"relCanonicalName\",\n",
      "        \"documentID\",\n",
      "        count(*) as \"mAB_doc\"\n",
      "     from \n",
      "     (select * from ADS.\"SIRE1.1\"\n",
      "     fetch first 300000000 rows only)\n",
      "     group by ( \"subject/instanceName_up\",\n",
      "                \"subject/typeType\",\n",
      "                \"object/instanceName_up\",\n",
      "                \"object/typeType\",\n",
      "                \"relCanonicalName\",\n",
      "                \"documentID\"\n",
      "              )\n",
      "     )\n",
      "group by (  \"subject/instanceName_up\",\n",
      "            \"subject/typeType\",\n",
      "            \"object/instanceName_up\",\n",
      "            \"object/typeType\",\n",
      "            \"relCanonicalName\"\n",
      "         )\n",
      ")\n",
      "Where \"mAB\" > 1;\n"
     ]
    }
   ],
   "source": [
    "dump_path = dir_db2+'dump_v%(db_v)s_minmentions%(min_mentions)s.del' %{\"db_v\":DB_V,\"min_mentions\":MIN_MENTIONS}\n",
    "sql = '''\n",
    "connect to KG_R%(db_v)s;\n",
    "export to %(dump_path)s of del\n",
    "SELECT * FROM\n",
    "(Select \n",
    "    \"subject/instanceName_up\",\n",
    "    \"subject/typeType\",\n",
    "    \"object/instanceName_up\",\n",
    "    \"object/typeType\",\n",
    "    \"relCanonicalName\",\n",
    "    SUM(\"mAB_doc\") as \"mAB\",\n",
    "    count(*) as \"n_docs\"\n",
    "from (\n",
    "     Select\n",
    "        \"subject/instanceName_up\",\n",
    "        \"subject/typeType\",\n",
    "        \"object/instanceName_up\",\n",
    "        \"object/typeType\",\n",
    "        \"relCanonicalName\",\n",
    "        \"documentID\",\n",
    "        count(*) as \"mAB_doc\"\n",
    "     from \n",
    "     (select * from ADS.\"SIRE1.1\"\n",
    "     fetch first %(row_limit)i rows only)\n",
    "     group by ( \"subject/instanceName_up\",\n",
    "                \"subject/typeType\",\n",
    "                \"object/instanceName_up\",\n",
    "                \"object/typeType\",\n",
    "                \"relCanonicalName\",\n",
    "                \"documentID\"\n",
    "              )\n",
    "     )\n",
    "group by (  \"subject/instanceName_up\",\n",
    "            \"subject/typeType\",\n",
    "            \"object/instanceName_up\",\n",
    "            \"object/typeType\",\n",
    "            \"relCanonicalName\"\n",
    "         )\n",
    ")\n",
    "Where \"mAB\" > %(min_mab)i;''' % {\"db_v\":DB_V,\"dump_path\": dump_path, \"min_mab\": MIN_MENTIONS-1, \"row_limit\": 300000000}\n",
    "\n",
    "print sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Run the above SQL in db2 on wd-app03.\n",
    "Then, copy over the file to the path: local_path_reltable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relcols = ['A',\n",
    "           'At',\n",
    "           'B',\n",
    "           'Bt',\n",
    "           'reltype',\n",
    "           'mAB',\n",
    "           'nDocs']\n",
    "local_path_reltable = '%(dir_local)sdump_v%(db_v)s_minmentions%(min_mentions)s.del' %{\"dir_local\":dir_local,\"db_v\":DB_V,\"min_mentions\":MIN_MENTIONS}\n",
    "reldata = pandas.read_csv(local_path_reltable,header=None,names=relcols,nrows=1000,na_filter=True).dropna()\n",
    "len(reldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reldata['key_A'] = reldata['A'].map(str)+'_'+reldata['At']\n",
    "reldata['key_B'] = reldata['B'].map(str)+'_'+reldata['Bt']\n",
    "entities = pandas.DataFrame(pandas.unique(reldata[['key_A','key_B']].values.flatten()),columns = ['name_type'])\n",
    "entities['idx'] = pandas.Series(range(len(entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.set_index('name_type',inplace=True)\n",
    "entity_to_index = entities.to_dict()['idx']\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Atest(row):\n",
    "    key = row['A'] + '_'+row['At']\n",
    "    try:\n",
    "        return entity_to_index[key]\n",
    "    except KeyError,e:\n",
    "        #print 'error'\n",
    "        return -1\n",
    "def Btest(row):\n",
    "    key = row['B']+'_'+row['Bt']\n",
    "    try:\n",
    "        return entity_to_index[key]\n",
    "    except KeyError,e:\n",
    "        #print 'error'\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reldata['Aindex'] = reldata.apply(func = Atest,axis=1)\n",
    "reldata['Bindex'] = reldata.apply(func = Btest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833\n"
     ]
    }
   ],
   "source": [
    "reldata.drop(labels=['At','Bt','reltype','mAB','nDocs'],axis = 1, inplace=True)\n",
    "reldata = reldata[(~(reldata['Aindex']==-1))&(~(reldata['Bindex']==-1))]\n",
    "print len(reldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Sampling: reldata's A and B fields, as is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1],\n",
       "       [   2,    3],\n",
       "       [   4,    5],\n",
       "       ..., \n",
       "       [1133, 1137],\n",
       "       [1133, 1138],\n",
       "       [1133, 1139]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reldata[['Aindex','Bindex']].as_matrix()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle.dump((data,entity_to_index),open(dir_local+'traindata'+standard_suffix+'.pkl','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ceph/vinith/kg/embedding/traindata_distinct__v233_minmentions2_style_derived_uniques.pkl\n"
     ]
    }
   ],
   "source": [
    "print dir_local+'traindata'+standard_suffix+'.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.model_sampling' from 'models/model_sampling.py'>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models.model_randnegatives\n",
    "reload(models.model_randnegatives)\n",
    "import models.model_sampling\n",
    "reload(models.model_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training embedding with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685 10\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 300\n",
    "LR = 50\n",
    "N_EDGES = 500\n",
    "batch_size =50\n",
    "dim = 10\n",
    "\n",
    "n_entities = max(data[:N_EDGES].flatten()) + 1#max(entities['idx'])\n",
    "n_batches = int(math.ceil(float(N_EDGES)/float(batch_size)))\n",
    "print n_entities,n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LP = models.model_sampling.simple_linkpred(dim=dim,n_entities=n_entities,batch_size=batch_size,validation_samples=1)\n",
    "#train = LP.get_training_fn(data[:N_EDGES].astype(numpy.int32))\n",
    "train = LP.get_adagrad_fn(data[:N_EDGES].astype(numpy.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train epoch-by-epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1]],\n",
       "\n",
       "       [[1]],\n",
       "\n",
       "       [[1]],\n",
       "\n",
       "       [[0]]], dtype=int8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(LP.bithash_1s[0]).eval({LP.x1_idxs:numpy.asarray([1,2,3,4],dtype=numpy.int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63392897]\n",
      " [ 0.37035761]\n",
      " [ 0.32822116]\n",
      " [ 0.56210718]]\n",
      "[[ 0.71407179]\n",
      " [ 0.42312224]\n",
      " [ 0.67989387]\n",
      " [ 0.64741522]]\n",
      "[ 0.62604697  0.62713215  0.60782911  0.62675276]\n",
      "[[ 0.73105858]\n",
      " [ 0.73105858]\n",
      " [ 0.5       ]\n",
      " [ 0.73105858]]\n",
      "[[ 0.13583704  0.12713215  0.10782911  0.12675276]\n",
      " [ 0.13583704  0.12713215  0.10782911  0.12675276]\n",
      " [ 0.13583704  0.12713215  0.10782911  0.12675276]\n",
      " [ 0.13583704  0.12713215  0.10782911  0.12675276]]\n"
     ]
    }
   ],
   "source": [
    "print LP.x1_emb.eval({LP.x1_idxs:numpy.asarray([1,2,3,4],dtype=numpy.int32)})\n",
    "print LP.x2_emb.eval({LP.x2_idxs:numpy.asarray([5,6,7,8],dtype=numpy.int32)})\n",
    "print LP.exp_p1.eval({LP.x1_idxs:numpy.asarray([120,2,3,4],dtype=numpy.int32),LP.x2_idxs:numpy.asarray([5,6,7,8],dtype=numpy.int32)})\n",
    "print LP.bit_p1.eval({LP.x1_idxs:numpy.asarray([1,2,3,4],dtype=numpy.int32),LP.x2_idxs:numpy.asarray([5,6,7,8],dtype=numpy.int32)})\n",
    "print (LP.exp_p1-LP.bit_p1).eval({LP.x1_idxs:numpy.asarray([1,2,3,4],dtype=numpy.int32),LP.x2_idxs:numpy.asarray([5,6,7,8],dtype=numpy.int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 \tlatest loss:  0.109496906192 \tsampled loss:  0.205966915539 \ttime-per-epoch:  944.805145264\n",
      "epoch:  1 \tlatest loss:  0.13219373776 \tsampled loss:  0.220611139149 \ttime-per-epoch:  599.641799927\n",
      "epoch:  2 \tlatest loss:  0.117683056536 \tsampled loss:  0.225212559697 \ttime-per-epoch:  567.798614502\n",
      "epoch:  3 \tlatest loss:  0.146405900671 \tsampled loss:  0.216116341999 \ttime-per-epoch:  567.998886108\n",
      "epoch:  4 \tlatest loss:  0.0898950948049 \tsampled loss:  0.192256444346 \ttime-per-epoch:  565.795898438\n",
      "epoch:  5 \tlatest loss:  0.0865235173959 \tsampled loss:  0.1813256125 \ttime-per-epoch:  570.154190063\n",
      "epoch:  6 \tlatest loss:  0.0784859594941 \tsampled loss:  0.162192257851 \ttime-per-epoch:  562.124252319\n",
      "epoch:  7 \tlatest loss:  0.0799127920359 \tsampled loss:  0.139985207636 \ttime-per-epoch:  558.481216431\n",
      "epoch:  8 \tlatest loss:  0.121167195225 \tsampled loss:  0.188175708613 \ttime-per-epoch:  559.320449829\n",
      "epoch:  9 \tlatest loss:  0.107316555866 \tsampled loss:  0.193905120942 \ttime-per-epoch:  567.321777344\n",
      "epoch:  10 \tlatest loss:  0.0856060108464 \tsampled loss:  0.186095230558 \ttime-per-epoch:  564.71824646\n",
      "epoch:  11 \tlatest loss:  0.0683006743031 \tsampled loss:  0.183811112388 \ttime-per-epoch:  561.046600342\n",
      "epoch:  12 \tlatest loss:  0.0940229722045 \tsampled loss:  0.196792726944 \ttime-per-epoch:  558.643341064\n",
      "epoch:  13 \tlatest loss:  0.106590511022 \tsampled loss:  0.160775282972 \ttime-per-epoch:  569.725036621\n",
      "epoch:  14 \tlatest loss:  0.121346133476 \tsampled loss:  0.196757978395 \ttime-per-epoch:  565.204620361\n",
      "epoch:  15 \tlatest loss:  0.0685773986268 \tsampled loss:  0.147033526981 \ttime-per-epoch:  555.286407471\n",
      "epoch:  16 \tlatest loss:  0.115573076759 \tsampled loss:  0.166795282143 \ttime-per-epoch:  557.880401611\n",
      "epoch:  17 \tlatest loss:  0.0983123297429 \tsampled loss:  0.166248687319 \ttime-per-epoch:  564.279556274\n",
      "epoch:  18 \tlatest loss:  0.0544101352947 \tsampled loss:  0.144109915793 \ttime-per-epoch:  555.114746094\n",
      "epoch:  19 \tlatest loss:  0.0961508167114 \tsampled loss:  0.167433952318 \ttime-per-epoch:  651.273727417\n",
      "epoch:  20 \tlatest loss:  0.118560841176 \tsampled loss:  0.208604266105 \ttime-per-epoch:  582.323074341\n",
      "epoch:  21 \tlatest loss:  0.110817430703 \tsampled loss:  0.198060551595 \ttime-per-epoch:  586.605072021\n",
      "epoch:  22 \tlatest loss:  0.126535621674 \tsampled loss:  0.208612168061 \ttime-per-epoch:  563.077926636\n",
      "epoch:  23 \tlatest loss:  0.11699659295 \tsampled loss:  0.175035783395 \ttime-per-epoch:  564.165115356\n",
      "epoch:  24 \tlatest loss:  0.116799202655 \tsampled loss:  0.191051545524 \ttime-per-epoch:  562.162399292\n",
      "epoch:  25 \tlatest loss:  0.0950302770718 \tsampled loss:  0.164488316699 \ttime-per-epoch:  572.280883789\n",
      "epoch:  26 \tlatest loss:  0.109220010009 \tsampled loss:  0.203706470148 \ttime-per-epoch:  564.165115356\n",
      "epoch:  27 \tlatest loss:  0.123822545926 \tsampled loss:  0.221630478318 \ttime-per-epoch:  554.313659668\n",
      "epoch:  28 \tlatest loss:  0.11764316536 \tsampled loss:  0.176830222327 \ttime-per-epoch:  580.921173096\n",
      "epoch:  29 \tlatest loss:  0.0902111957373 \tsampled loss:  0.149471974757 \ttime-per-epoch:  591.516494751\n",
      "epoch:  30 \tlatest loss:  0.0967295850848 \tsampled loss:  0.172965888025 \ttime-per-epoch:  570.917129517\n",
      "epoch:  31 \tlatest loss:  0.080020652627 \tsampled loss:  0.15655047252 \ttime-per-epoch:  559.635162354\n",
      "epoch:  32 \tlatest loss:  0.0872665817167 \tsampled loss:  0.203326942737 \ttime-per-epoch:  558.156967163\n",
      "epoch:  33 \tlatest loss:  0.102136528067 \tsampled loss:  0.163843865236 \ttime-per-epoch:  575.799942017\n",
      "epoch:  34 \tlatest loss:  0.118292284692 \tsampled loss:  0.227930675664 \ttime-per-epoch:  573.482513428\n",
      "epoch:  35 \tlatest loss:  0.0857691191246 \tsampled loss:  0.137188478946 \ttime-per-epoch:  567.960739136\n",
      "epoch:  36 \tlatest loss:  0.121634625104 \tsampled loss:  0.1878807761 \ttime-per-epoch:  564.527511597\n",
      "epoch:  37 \tlatest loss:  0.107400085107 \tsampled loss:  0.17959778781 \ttime-per-epoch:  567.874908447\n",
      "epoch:  38 \tlatest loss:  0.0963465642973 \tsampled loss:  0.161772941731 \ttime-per-epoch:  564.35585022\n",
      "epoch:  39 \tlatest loss:  0.069822055912 \tsampled loss:  0.168636578116 \ttime-per-epoch:  568.27545166\n",
      "epoch:  40 \tlatest loss:  0.0718349861979 \tsampled loss:  0.139347375424 \ttime-per-epoch:  565.719604492\n",
      "epoch:  41 \tlatest loss:  0.123661107609 \tsampled loss:  0.198952522129 \ttime-per-epoch:  567.321777344\n",
      "epoch:  42 \tlatest loss:  0.0863254290809 \tsampled loss:  0.126098327241 \ttime-per-epoch:  571.241378784\n",
      "epoch:  43 \tlatest loss:  0.084721066238 \tsampled loss:  0.14829830484 \ttime-per-epoch:  566.120147705\n",
      "epoch:  44 \tlatest loss:  0.0879041052327 \tsampled loss:  0.16795042672 \ttime-per-epoch:  561.323165894\n",
      "epoch:  45 \tlatest loss:  0.0773356118777 \tsampled loss:  0.149865686595 \ttime-per-epoch:  562.27684021\n",
      "epoch:  46 \tlatest loss:  0.0779190630279 \tsampled loss:  0.147191376675 \ttime-per-epoch:  563.840866089\n",
      "epoch:  47 \tlatest loss:  0.0573139071372 \tsampled loss:  0.150172208051 \ttime-per-epoch:  556.879043579\n",
      "epoch:  48 \tlatest loss:  0.0947136183082 \tsampled loss:  0.13808651643 \ttime-per-epoch:  555.438995361\n",
      "epoch:  49 \tlatest loss:  0.115169720842 \tsampled loss:  0.200564333982 \ttime-per-epoch:  566.368103027\n",
      "epoch:  50 \tlatest loss:  0.138675886632 \tsampled loss:  0.1928781622 \ttime-per-epoch:  615.205764771\n",
      "epoch:  51 \tlatest loss:  0.110299599782 \tsampled loss:  0.175346093769 \ttime-per-epoch:  563.316345215\n",
      "epoch:  52 \tlatest loss:  0.11474989422 \tsampled loss:  0.204894798654 \ttime-per-epoch:  558.156967163\n",
      "epoch:  53 \tlatest loss:  0.0813272802032 \tsampled loss:  0.175596927983 \ttime-per-epoch:  573.959350586\n",
      "epoch:  54 \tlatest loss:  0.0846814209197 \tsampled loss:  0.158037684787 \ttime-per-epoch:  561.075210571\n",
      "epoch:  55 \tlatest loss:  0.135480863472 \tsampled loss:  0.224314277933 \ttime-per-epoch:  560.235977173\n",
      "epoch:  56 \tlatest loss:  0.0923534362707 \tsampled loss:  0.165258580787 \ttime-per-epoch:  558.319091797\n",
      "epoch:  57 \tlatest loss:  0.106790705261 \tsampled loss:  0.173464012083 \ttime-per-epoch:  565.204620361\n",
      "epoch:  58 \tlatest loss:  0.103844788207 \tsampled loss:  0.205817263812 \ttime-per-epoch:  567.474365234\n",
      "epoch:  59 \tlatest loss:  0.149695897865 \tsampled loss:  0.221363236624 \ttime-per-epoch:  560.04524231\n",
      "epoch:  60 \tlatest loss:  0.119751617484 \tsampled loss:  0.245601920606 \ttime-per-epoch:  588.407516479\n",
      "epoch:  61 \tlatest loss:  0.0860679147107 \tsampled loss:  0.185484293438 \ttime-per-epoch:  599.517822266\n",
      "epoch:  62 \tlatest loss:  0.0847213720345 \tsampled loss:  0.162178590601 \ttime-per-epoch:  583.67729187\n",
      "epoch:  63 \tlatest loss:  0.122696949111 \tsampled loss:  0.171080089369 \ttime-per-epoch:  572.080612183\n",
      "epoch:  64 \tlatest loss:  0.0676781827823 \tsampled loss:  0.148726685227 \ttime-per-epoch:  577.516555786\n",
      "epoch:  65 \tlatest loss:  0.0744205030242 \tsampled loss:  0.130566233151 \ttime-per-epoch:  570.678710938\n",
      "epoch:  66 \tlatest loss:  0.0956331100373 \tsampled loss:  0.180828864755 \ttime-per-epoch:  563.116073608\n",
      "epoch:  67 \tlatest loss:  0.0713063998438 \tsampled loss:  0.137541616739 \ttime-per-epoch:  564.365386963\n",
      "epoch:  68 \tlatest loss:  0.101024142325 \tsampled loss:  0.177317768024 \ttime-per-epoch:  574.884414673\n",
      "epoch:  69 \tlatest loss:  0.14490160874 \tsampled loss:  0.216338184875 \ttime-per-epoch:  581.159591675\n",
      "epoch:  70 \tlatest loss:  0.0839152349994 \tsampled loss:  0.185718527501 \ttime-per-epoch:  569.324493408\n",
      "epoch:  71 \tlatest loss:  0.0902874814947 \tsampled loss:  0.172841827998 \ttime-per-epoch:  564.041137695\n",
      "epoch:  72 \tlatest loss:  0.0772031702851 \tsampled loss:  0.146315119868 \ttime-per-epoch:  559.759140015\n",
      "epoch:  73 \tlatest loss:  0.0928837225102 \tsampled loss:  0.183461877009 \ttime-per-epoch:  567.398071289\n",
      "epoch:  74 \tlatest loss:  0.0898931247727 \tsampled loss:  0.147093841733 \ttime-per-epoch:  568.838119507\n",
      "epoch:  75 \tlatest loss:  0.102669196565 \tsampled loss:  0.20155319258 \ttime-per-epoch:  569.524765015\n",
      "epoch:  76 \tlatest loss:  0.105104899474 \tsampled loss:  0.236702564823 \ttime-per-epoch:  576.524734497\n",
      "epoch:  77 \tlatest loss:  0.121061778374 \tsampled loss:  0.199394822731 \ttime-per-epoch:  570.56427002\n",
      "epoch:  78 \tlatest loss:  0.126375409769 \tsampled loss:  0.26040806524 \ttime-per-epoch:  568.914413452\n",
      "epoch:  79 \tlatest loss:  0.0857261151458 \tsampled loss:  0.163876973691 \ttime-per-epoch:  571.517944336\n",
      "epoch:  80 \tlatest loss:  0.0881155424827 \tsampled loss:  0.139827280169 \ttime-per-epoch:  561.122894287\n",
      "epoch:  81 \tlatest loss:  0.0770015199788 \tsampled loss:  0.15932019598 \ttime-per-epoch:  572.834014893\n",
      "epoch:  82 \tlatest loss:  0.176744303824 \tsampled loss:  0.263263077367 \ttime-per-epoch:  564.441680908\n",
      "epoch:  83 \tlatest loss:  0.117577340761 \tsampled loss:  0.243462050162 \ttime-per-epoch:  571.479797363\n",
      "epoch:  84 \tlatest loss:  0.115390578153 \tsampled loss:  0.222201150081 \ttime-per-epoch:  561.838150024\n",
      "epoch:  85 \tlatest loss:  0.0479199133028 \tsampled loss:  0.14018913834 \ttime-per-epoch:  566.673278809\n",
      "epoch:  86 \tlatest loss:  0.0965190412207 \tsampled loss:  0.164344790158 \ttime-per-epoch:  557.327270508\n",
      "epoch:  87 \tlatest loss:  0.0833466259429 \tsampled loss:  0.15721047909 \ttime-per-epoch:  579.557418823\n",
      "epoch:  88 \tlatest loss:  0.113114155294 \tsampled loss:  0.201893705702 \ttime-per-epoch:  564.031600952\n",
      "epoch:  89 \tlatest loss:  0.107117204614 \tsampled loss:  0.187801600194 \ttime-per-epoch:  574.760437012\n",
      "epoch:  90 \tlatest loss:  0.0850162536535 \tsampled loss:  0.195794709395 \ttime-per-epoch:  570.440292358\n",
      "epoch:  91 \tlatest loss:  0.0807823471732 \tsampled loss:  0.174409884166 \ttime-per-epoch:  562.200546265\n",
      "epoch:  92 \tlatest loss:  0.0778351189021 \tsampled loss:  0.153347868303 \ttime-per-epoch:  562.000274658\n",
      "epoch:  93 \tlatest loss:  0.117035809021 \tsampled loss:  0.21044728224 \ttime-per-epoch:  559.44442749\n",
      "epoch:  94 \tlatest loss:  0.100275178063 \tsampled loss:  0.213485989282 \ttime-per-epoch:  552.759170532\n",
      "epoch:  95 \tlatest loss:  0.0851615452572 \tsampled loss:  0.163897325612 \ttime-per-epoch:  557.155609131\n",
      "epoch:  96 \tlatest loss:  0.0970393088977 \tsampled loss:  0.172008226157 \ttime-per-epoch:  560.121536255\n",
      "epoch:  97 \tlatest loss:  0.0866886171401 \tsampled loss:  0.201143099424 \ttime-per-epoch:  560.674667358\n",
      "epoch:  98 \tlatest loss:  0.0633191266497 \tsampled loss:  0.176830212395 \ttime-per-epoch:  561.847686768\n",
      "epoch:  99 \tlatest loss:  0.0997217174419 \tsampled loss:  0.208137881678 \ttime-per-epoch:  569.200515747\n",
      "epoch:  100 \tlatest loss:  0.0764686119991 \tsampled loss:  0.144482534603 \ttime-per-epoch:  559.08203125\n",
      "epoch:  101 \tlatest loss:  0.0763602815347 \tsampled loss:  0.166464469271 \ttime-per-epoch:  564.441680908\n",
      "epoch:  102 \tlatest loss:  0.106876421309 \tsampled loss:  0.183216387601 \ttime-per-epoch:  558.395385742\n",
      "epoch:  103 \tlatest loss:  0.0713441435013 \tsampled loss:  0.164166706663 \ttime-per-epoch:  580.043792725\n",
      "epoch:  104 \tlatest loss:  0.119626764468 \tsampled loss:  0.220867976956 \ttime-per-epoch:  576.162338257\n",
      "epoch:  105 \tlatest loss:  0.095104108976 \tsampled loss:  0.182867367703 \ttime-per-epoch:  581.922531128\n",
      "epoch:  106 \tlatest loss:  0.103037962856 \tsampled loss:  0.214903038157 \ttime-per-epoch:  560.1978302\n",
      "epoch:  107 \tlatest loss:  0.0826527712937 \tsampled loss:  0.184206405706 \ttime-per-epoch:  556.440353394\n",
      "epoch:  108 \tlatest loss:  0.0797639030547 \tsampled loss:  0.160376991503 \ttime-per-epoch:  568.675994873\n",
      "epoch:  109 \tlatest loss:  0.0847114274116 \tsampled loss:  0.136376537547 \ttime-per-epoch:  563.440322876\n",
      "epoch:  110 \tlatest loss:  0.0983355539123 \tsampled loss:  0.198917472561 \ttime-per-epoch:  566.79725647\n",
      "epoch:  111 \tlatest loss:  0.0869934526282 \tsampled loss:  0.124264744501 \ttime-per-epoch:  558.681488037\n",
      "epoch:  112 \tlatest loss:  0.097826444609 \tsampled loss:  0.196910296909 \ttime-per-epoch:  557.565689087\n",
      "epoch:  113 \tlatest loss:  0.0863263706009 \tsampled loss:  0.146358986565 \ttime-per-epoch:  561.208724976\n",
      "epoch:  114 \tlatest loss:  0.133683887452 \tsampled loss:  0.230137558831 \ttime-per-epoch:  564.002990723\n",
      "epoch:  115 \tlatest loss:  0.116729521888 \tsampled loss:  0.234362513446 \ttime-per-epoch:  564.880371094\n",
      "epoch:  116 \tlatest loss:  0.0809588420009 \tsampled loss:  0.169655816846 \ttime-per-epoch:  557.718276978\n",
      "epoch:  117 \tlatest loss:  0.0801413559447 \tsampled loss:  0.160675107228 \ttime-per-epoch:  564.203262329\n",
      "epoch:  118 \tlatest loss:  0.0913008971212 \tsampled loss:  0.145050162368 \ttime-per-epoch:  611.791610718\n",
      "epoch:  119 \tlatest loss:  0.102443916523 \tsampled loss:  0.181138209982 \ttime-per-epoch:  560.760498047\n",
      "epoch:  120 \tlatest loss:  0.0694459288589 \tsampled loss:  0.123467698476 \ttime-per-epoch:  560.083389282\n",
      "epoch:  121 \tlatest loss:  0.132139128044 \tsampled loss:  0.208345691041 \ttime-per-epoch:  565.481185913\n",
      "epoch:  122 \tlatest loss:  0.108116988127 \tsampled loss:  0.208990678916 \ttime-per-epoch:  558.681488037\n",
      "epoch:  123 \tlatest loss:  0.0662452294813 \tsampled loss:  0.131949153817 \ttime-per-epoch:  558.681488037\n",
      "epoch:  124 \tlatest loss:  0.0695094399257 \tsampled loss:  0.148182999502 \ttime-per-epoch:  556.716918945\n",
      "epoch:  125 \tlatest loss:  0.113703364937 \tsampled loss:  0.184380111781 \ttime-per-epoch:  565.843582153\n",
      "epoch:  126 \tlatest loss:  0.104440373341 \tsampled loss:  0.185952758391 \ttime-per-epoch:  554.876327515\n",
      "epoch:  127 \tlatest loss:  0.0886667002792 \tsampled loss:  0.173191635237 \ttime-per-epoch:  558.004379272\n",
      "epoch:  128 \tlatest loss:  0.0631498992214 \tsampled loss:  0.143047550094 \ttime-per-epoch:  560.111999512\n",
      "epoch:  129 \tlatest loss:  0.106454123041 \tsampled loss:  0.14844907008 \ttime-per-epoch:  567.36946106\n",
      "epoch:  130 \tlatest loss:  0.103727414844 \tsampled loss:  0.202264588404 \ttime-per-epoch:  562.839508057\n",
      "epoch:  131 \tlatest loss:  0.103966921052 \tsampled loss:  0.192941696544 \ttime-per-epoch:  577.163696289\n",
      "epoch:  132 \tlatest loss:  0.152793830438 \tsampled loss:  0.248852816716 \ttime-per-epoch:  574.398040771\n",
      "epoch:  133 \tlatest loss:  0.0951592088587 \tsampled loss:  0.174619090431 \ttime-per-epoch:  564.088821411\n",
      "epoch:  134 \tlatest loss:  0.0917621960601 \tsampled loss:  0.188049943662 \ttime-per-epoch:  555.715560913\n",
      "epoch:  135 \tlatest loss:  0.113061103991 \tsampled loss:  0.170633747276 \ttime-per-epoch:  552.759170532\n",
      "epoch:  136 \tlatest loss:  0.086022831972 \tsampled loss:  0.152291921415 \ttime-per-epoch:  561.676025391\n",
      "epoch:  137 \tlatest loss:  0.105570662196 \tsampled loss:  0.168694370812 \ttime-per-epoch:  577.116012573\n",
      "epoch:  138 \tlatest loss:  0.115223804274 \tsampled loss:  0.221940569145 \ttime-per-epoch:  568.161010742\n",
      "epoch:  139 \tlatest loss:  0.122702906711 \tsampled loss:  0.203343965484 \ttime-per-epoch:  562.362670898\n",
      "epoch:  140 \tlatest loss:  0.0973851376698 \tsampled loss:  0.202844459847 \ttime-per-epoch:  563.478469849\n",
      "epoch:  141 \tlatest loss:  0.0734077158607 \tsampled loss:  0.143717174384 \ttime-per-epoch:  689.077377319\n",
      "epoch:  142 \tlatest loss:  0.0668910866132 \tsampled loss:  0.130726608411 \ttime-per-epoch:  568.246841431\n",
      "epoch:  143 \tlatest loss:  0.0656940105285 \tsampled loss:  0.182481968824 \ttime-per-epoch:  557.203292847\n",
      "epoch:  144 \tlatest loss:  0.092805032457 \tsampled loss:  0.147826129724 \ttime-per-epoch:  557.718276978\n",
      "epoch:  145 \tlatest loss:  0.11427606196 \tsampled loss:  0.210824983219 \ttime-per-epoch:  568.313598633\n",
      "epoch:  146 \tlatest loss:  0.0746178532816 \tsampled loss:  0.187341338848 \ttime-per-epoch:  572.519302368\n",
      "epoch:  147 \tlatest loss:  0.0926844564823 \tsampled loss:  0.163815305022 \ttime-per-epoch:  563.39263916\n",
      "epoch:  148 \tlatest loss:  0.0896403995454 \tsampled loss:  0.162058429256 \ttime-per-epoch:  552.520751953\n",
      "epoch:  149 \tlatest loss:  0.0766453685326 \tsampled loss:  0.154489689181 \ttime-per-epoch:  573.873519897\n",
      "epoch:  150 \tlatest loss:  0.102341766279 \tsampled loss:  0.166479678676 \ttime-per-epoch:  553.684234619\n",
      "epoch:  151 \tlatest loss:  0.078132881489 \tsampled loss:  0.166937138551 \ttime-per-epoch:  567.674636841\n",
      "epoch:  152 \tlatest loss:  0.0826955080424 \tsampled loss:  0.183165652676 \ttime-per-epoch:  553.0834198\n",
      "epoch:  153 \tlatest loss:  0.0824808438659 \tsampled loss:  0.174678132921 \ttime-per-epoch:  571.918487549\n",
      "epoch:  154 \tlatest loss:  0.0578102871933 \tsampled loss:  0.112724938051 \ttime-per-epoch:  548.477172852\n",
      "epoch:  155 \tlatest loss:  0.0823731842533 \tsampled loss:  0.164929776864 \ttime-per-epoch:  668.640136719\n",
      "epoch:  156 \tlatest loss:  0.104674648064 \tsampled loss:  0.155093443663 \ttime-per-epoch:  569.200515747\n",
      "epoch:  157 \tlatest loss:  0.0872545464035 \tsampled loss:  0.167650689239 \ttime-per-epoch:  570.56427002\n",
      "epoch:  158 \tlatest loss:  0.0643795917437 \tsampled loss:  0.150679163333 \ttime-per-epoch:  565.528869629\n",
      "epoch:  159 \tlatest loss:  0.0995827079432 \tsampled loss:  0.179958674305 \ttime-per-epoch:  560.283660889\n",
      "epoch:  160 \tlatest loss:  0.110864226614 \tsampled loss:  0.206165783222 \ttime-per-epoch:  563.640594482\n",
      "epoch:  161 \tlatest loss:  0.0943706679846 \tsampled loss:  0.172653941454 \ttime-per-epoch:  565.0806427\n",
      "epoch:  162 \tlatest loss:  0.0853659845822 \tsampled loss:  0.179760674751 \ttime-per-epoch:  563.526153564\n",
      "epoch:  163 \tlatest loss:  0.0715616880253 \tsampled loss:  0.164439688668 \ttime-per-epoch:  559.120178223\n",
      "epoch:  164 \tlatest loss:  0.0897370609375 \tsampled loss:  0.160377547206 \ttime-per-epoch:  557.241439819\n",
      "epoch:  165 \tlatest loss:  0.0743422450742 \tsampled loss:  0.133137930899 \ttime-per-epoch:  566.082000732\n",
      "epoch:  166 \tlatest loss:  0.0827466272389 \tsampled loss:  0.162812463076 \ttime-per-epoch:  562.877655029\n",
      "epoch:  167 \tlatest loss:  0.0931625616579 \tsampled loss:  0.175486934909 \ttime-per-epoch:  559.959411621\n",
      "epoch:  168 \tlatest loss:  0.109682788476 \tsampled loss:  0.209781312397 \ttime-per-epoch:  564.517974854\n",
      "epoch:  169 \tlatest loss:  0.128001419985 \tsampled loss:  0.204003107271 \ttime-per-epoch:  582.399368286\n",
      "epoch:  170 \tlatest loss:  0.0818549366587 \tsampled loss:  0.165413437245 \ttime-per-epoch:  563.764572144\n",
      "epoch:  171 \tlatest loss:  0.0778141818455 \tsampled loss:  0.176587341506 \ttime-per-epoch:  558.843612671\n",
      "epoch:  172 \tlatest loss:  0.0861791776597 \tsampled loss:  0.19906093638 \ttime-per-epoch:  560.1978302\n",
      "epoch:  173 \tlatest loss:  0.0868206828219 \tsampled loss:  0.152213295522 \ttime-per-epoch:  570.92666626\n",
      "epoch:  174 \tlatest loss:  0.0941839582896 \tsampled loss:  0.169963824811 \ttime-per-epoch:  564.71824646\n",
      "epoch:  175 \tlatest loss:  0.0628617266511 \tsampled loss:  0.160422766689 \ttime-per-epoch:  555.391311646\n",
      "epoch:  176 \tlatest loss:  0.0771556965069 \tsampled loss:  0.161697693438 \ttime-per-epoch:  567.52204895\n",
      "epoch:  177 \tlatest loss:  0.0950171406386 \tsampled loss:  0.168436897997 \ttime-per-epoch:  566.844940186\n",
      "epoch:  178 \tlatest loss:  0.142662428603 \tsampled loss:  0.231597364144 \ttime-per-epoch:  561.285018921\n",
      "epoch:  179 \tlatest loss:  0.0886594180318 \tsampled loss:  0.166928902197 \ttime-per-epoch:  570.240020752\n",
      "epoch:  180 \tlatest loss:  0.0759366370545 \tsampled loss:  0.207213866166 \ttime-per-epoch:  565.83404541\n",
      "epoch:  181 \tlatest loss:  0.103903953084 \tsampled loss:  0.159601118941 \ttime-per-epoch:  569.362640381\n",
      "epoch:  182 \tlatest loss:  0.10692534317 \tsampled loss:  0.205582332618 \ttime-per-epoch:  568.723678589\n",
      "epoch:  183 \tlatest loss:  0.116173634572 \tsampled loss:  0.187155111049 \ttime-per-epoch:  564.32723999\n",
      "epoch:  184 \tlatest loss:  0.0633697058994 \tsampled loss:  0.157473285057 \ttime-per-epoch:  561.5234375\n",
      "epoch:  185 \tlatest loss:  0.0930546493047 \tsampled loss:  0.134831730553 \ttime-per-epoch:  568.237304688\n",
      "epoch:  186 \tlatest loss:  0.106309405124 \tsampled loss:  0.225325756745 \ttime-per-epoch:  585.994720459\n",
      "epoch:  187 \tlatest loss:  0.100040436151 \tsampled loss:  0.160080626786 \ttime-per-epoch:  569.23866272\n",
      "epoch:  188 \tlatest loss:  0.0914523396949 \tsampled loss:  0.203811193823 \ttime-per-epoch:  568.6378479\n",
      "epoch:  189 \tlatest loss:  0.125384351321 \tsampled loss:  0.197549436231 \ttime-per-epoch:  570.726394653\n",
      "epoch:  190 \tlatest loss:  0.138169863562 \tsampled loss:  0.233347890858 \ttime-per-epoch:  574.884414673\n",
      "epoch:  191 \tlatest loss:  0.142702763217 \tsampled loss:  0.262581675537 \ttime-per-epoch:  567.922592163\n",
      "epoch:  192 \tlatest loss:  0.0874796412037 \tsampled loss:  0.134933031115 \ttime-per-epoch:  566.844940186\n",
      "epoch:  193 \tlatest loss:  0.106208980198 \tsampled loss:  0.206759093901 \ttime-per-epoch:  612.077713013\n",
      "epoch:  194 \tlatest loss:  0.0745560577826 \tsampled loss:  0.157108789839 \ttime-per-epoch:  583.114624023\n",
      "epoch:  195 \tlatest loss:  0.0582946899637 \tsampled loss:  0.145984419247 \ttime-per-epoch:  570.402145386\n",
      "epoch:  196 \tlatest loss:  0.0907440721924 \tsampled loss:  0.193472587991 \ttime-per-epoch:  576.276779175\n",
      "epoch:  197 \tlatest loss:  0.100427668528 \tsampled loss:  0.211085999181 \ttime-per-epoch:  575.723648071\n",
      "epoch:  198 \tlatest loss:  0.0696218351451 \tsampled loss:  0.178896070751 \ttime-per-epoch:  569.9634552\n",
      "epoch:  199 \tlatest loss:  0.0946682713449 \tsampled loss:  0.1872240948 \ttime-per-epoch:  566.244125366\n",
      "epoch:  200 \tlatest loss:  0.113971222654 \tsampled loss:  0.187263518685 \ttime-per-epoch:  568.923950195\n",
      "epoch:  201 \tlatest loss:  0.109869810988 \tsampled loss:  0.256820699527 \ttime-per-epoch:  688.962936401\n",
      "epoch:  202 \tlatest loss:  0.107847000715 \tsampled loss:  0.196158557731 \ttime-per-epoch:  561.761856079\n",
      "epoch:  203 \tlatest loss:  0.11807731737 \tsampled loss:  0.178734303925 \ttime-per-epoch:  554.084777832\n",
      "epoch:  204 \tlatest loss:  0.144348910727 \tsampled loss:  0.25748113969 \ttime-per-epoch:  553.23600769\n",
      "epoch:  205 \tlatest loss:  0.10935607519 \tsampled loss:  0.182423451358 \ttime-per-epoch:  570.001602173\n",
      "epoch:  206 \tlatest loss:  0.102894506372 \tsampled loss:  0.172088174712 \ttime-per-epoch:  558.757781982\n",
      "epoch:  207 \tlatest loss:  0.0953024918503 \tsampled loss:  0.193886107993 \ttime-per-epoch:  558.11882019\n",
      "epoch:  208 \tlatest loss:  0.103019621629 \tsampled loss:  0.177008729738 \ttime-per-epoch:  555.601119995\n",
      "epoch:  209 \tlatest loss:  0.0843263077963 \tsampled loss:  0.156782182524 \ttime-per-epoch:  560.04524231\n",
      "epoch:  210 \tlatest loss:  0.0992386428341 \tsampled loss:  0.18412989677 \ttime-per-epoch:  558.242797852\n",
      "epoch:  211 \tlatest loss:  0.105118374696 \tsampled loss:  0.195462912172 \ttime-per-epoch:  555.877685547\n",
      "epoch:  212 \tlatest loss:  0.105869367806 \tsampled loss:  0.209526786625 \ttime-per-epoch:  558.605194092\n",
      "epoch:  213 \tlatest loss:  0.0979146069056 \tsampled loss:  0.206145176211 \ttime-per-epoch:  569.000244141\n",
      "epoch:  214 \tlatest loss:  0.126185845963 \tsampled loss:  0.230426516724 \ttime-per-epoch:  564.565658569\n",
      "epoch:  215 \tlatest loss:  0.0883297705126 \tsampled loss:  0.174283466402 \ttime-per-epoch:  553.522109985\n",
      "epoch:  216 \tlatest loss:  0.0886069127787 \tsampled loss:  0.167489716128 \ttime-per-epoch:  557.155609131\n",
      "epoch:  217 \tlatest loss:  0.116182181058 \tsampled loss:  0.209529343218 \ttime-per-epoch:  562.677383423\n",
      "epoch:  218 \tlatest loss:  0.127910433563 \tsampled loss:  0.226831276414 \ttime-per-epoch:  551.357269287\n",
      "epoch:  219 \tlatest loss:  0.142255631356 \tsampled loss:  0.2581906599 \ttime-per-epoch:  567.359924316\n",
      "epoch:  220 \tlatest loss:  0.106241995619 \tsampled loss:  0.227346125509 \ttime-per-epoch:  560.598373413\n",
      "epoch:  221 \tlatest loss:  0.0939997313841 \tsampled loss:  0.173218557283 \ttime-per-epoch:  570.878982544\n",
      "epoch:  222 \tlatest loss:  0.0772412821846 \tsampled loss:  0.172364658951 \ttime-per-epoch:  623.121261597\n",
      "epoch:  223 \tlatest loss:  0.0731359386941 \tsampled loss:  0.204966711089 \ttime-per-epoch:  650.882720947\n",
      "epoch:  224 \tlatest loss:  0.0933923597191 \tsampled loss:  0.181236126334 \ttime-per-epoch:  584.316253662\n",
      "epoch:  225 \tlatest loss:  0.115392685082 \tsampled loss:  0.191765346922 \ttime-per-epoch:  567.88444519\n",
      "epoch:  226 \tlatest loss:  0.149408820828 \tsampled loss:  0.242285681887 \ttime-per-epoch:  559.44442749\n",
      "epoch:  227 \tlatest loss:  0.1294614921 \tsampled loss:  0.230270109166 \ttime-per-epoch:  556.764602661\n",
      "epoch:  228 \tlatest loss:  0.0949130030379 \tsampled loss:  0.150124848754 \ttime-per-epoch:  562.27684021\n",
      "epoch:  229 \tlatest loss:  0.130376070249 \tsampled loss:  0.208070870731 \ttime-per-epoch:  574.998855591\n",
      "epoch:  230 \tlatest loss:  0.0810063209604 \tsampled loss:  0.19707851107 \ttime-per-epoch:  565.843582153\n",
      "epoch:  231 \tlatest loss:  0.0593686727769 \tsampled loss:  0.123546420437 \ttime-per-epoch:  558.519363403\n",
      "epoch:  232 \tlatest loss:  0.107747068302 \tsampled loss:  0.200794129397 \ttime-per-epoch:  556.440353394\n",
      "epoch:  233 \tlatest loss:  0.0748339006693 \tsampled loss:  0.182436885673 \ttime-per-epoch:  569.000244141\n",
      "epoch:  234 \tlatest loss:  0.0843007445312 \tsampled loss:  0.147548040905 \ttime-per-epoch:  557.794570923\n",
      "epoch:  235 \tlatest loss:  0.128487499826 \tsampled loss:  0.233786062159 \ttime-per-epoch:  555.553436279\n",
      "epoch:  236 \tlatest loss:  0.101501367472 \tsampled loss:  0.207178953934 \ttime-per-epoch:  564.603805542\n",
      "epoch:  237 \tlatest loss:  0.0881856760568 \tsampled loss:  0.177692826065 \ttime-per-epoch:  561.761856079\n",
      "epoch:  238 \tlatest loss:  0.0876126840703 \tsampled loss:  0.201307139212 \ttime-per-epoch:  557.804107666\n",
      "epoch:  239 \tlatest loss:  0.0814875794275 \tsampled loss:  0.154533082349 \ttime-per-epoch:  564.765930176\n",
      "epoch:  240 \tlatest loss:  0.0781938763043 \tsampled loss:  0.148057876798 \ttime-per-epoch:  561.800003052\n",
      "epoch:  241 \tlatest loss:  0.105769219246 \tsampled loss:  0.203040053449 \ttime-per-epoch:  567.245483398\n",
      "epoch:  242 \tlatest loss:  0.0883031492024 \tsampled loss:  0.178574985221 \ttime-per-epoch:  565.395355225\n",
      "epoch:  243 \tlatest loss:  0.0843510652231 \tsampled loss:  0.183751338995 \ttime-per-epoch:  560.274124146\n",
      "epoch:  244 \tlatest loss:  0.060167146524 \tsampled loss:  0.131230298032 \ttime-per-epoch:  564.241409302\n",
      "epoch:  245 \tlatest loss:  0.0801648987552 \tsampled loss:  0.16045212811 \ttime-per-epoch:  572.881698608\n",
      "epoch:  246 \tlatest loss:  0.114003328 \tsampled loss:  0.194346570158 \ttime-per-epoch:  571.994781494\n",
      "epoch:  247 \tlatest loss:  0.0507609916919 \tsampled loss:  0.11925631729 \ttime-per-epoch:  559.44442749\n",
      "epoch:  248 \tlatest loss:  0.0993213423363 \tsampled loss:  0.185103887087 \ttime-per-epoch:  557.479858398\n",
      "epoch:  249 \tlatest loss:  0.0627191973579 \tsampled loss:  0.172253075871 \ttime-per-epoch:  563.96484375\n",
      "epoch:  250 \tlatest loss:  0.0964093186736 \tsampled loss:  0.177461160673 \ttime-per-epoch:  553.598403931\n",
      "epoch:  251 \tlatest loss:  0.109756361703 \tsampled loss:  0.21203208312 \ttime-per-epoch:  553.035736084\n",
      "epoch:  252 \tlatest loss:  0.0726194610505 \tsampled loss:  0.163821291841 \ttime-per-epoch:  557.804107666\n",
      "epoch:  253 \tlatest loss:  0.0954673274316 \tsampled loss:  0.180131483254 \ttime-per-epoch:  567.52204895\n",
      "epoch:  254 \tlatest loss:  0.110674537308 \tsampled loss:  0.176029181383 \ttime-per-epoch:  564.956665039\n",
      "epoch:  255 \tlatest loss:  0.124535736524 \tsampled loss:  0.250266627347 \ttime-per-epoch:  575.561523438\n",
      "epoch:  256 \tlatest loss:  0.103193638828 \tsampled loss:  0.193840535845 \ttime-per-epoch:  559.997558594\n",
      "epoch:  257 \tlatest loss:  0.0804903277035 \tsampled loss:  0.148370580239 \ttime-per-epoch:  566.234588623\n",
      "epoch:  258 \tlatest loss:  0.113520575458 \tsampled loss:  0.173066297726 \ttime-per-epoch:  566.759109497\n",
      "epoch:  259 \tlatest loss:  0.0983170211547 \tsampled loss:  0.170944613049 \ttime-per-epoch:  556.43081665\n",
      "epoch:  260 \tlatest loss:  0.0914559800873 \tsampled loss:  0.202356380789 \ttime-per-epoch:  561.637878418\n",
      "epoch:  261 \tlatest loss:  0.101778842458 \tsampled loss:  0.185293424105 \ttime-per-epoch:  569.915771484\n",
      "epoch:  262 \tlatest loss:  0.142265276989 \tsampled loss:  0.262343109853 \ttime-per-epoch:  568.046569824\n",
      "epoch:  263 \tlatest loss:  0.0786918600883 \tsampled loss:  0.193144621366 \ttime-per-epoch:  565.919876099\n",
      "epoch:  264 \tlatest loss:  0.0988751518657 \tsampled loss:  0.162377309129 \ttime-per-epoch:  574.798583984\n",
      "epoch:  265 \tlatest loss:  0.12457490787 \tsampled loss:  0.213581127589 \ttime-per-epoch:  574.321746826\n",
      "epoch:  266 \tlatest loss:  0.0788992194909 \tsampled loss:  0.18012957431 \ttime-per-epoch:  560.04524231\n",
      "epoch:  267 \tlatest loss:  0.092736239665 \tsampled loss:  0.175045291084 \ttime-per-epoch:  560.79864502\n",
      "epoch:  268 \tlatest loss:  0.0751088625459 \tsampled loss:  0.211277302216 \ttime-per-epoch:  559.921264648\n",
      "epoch:  269 \tlatest loss:  0.0724664256207 \tsampled loss:  0.1607383963 \ttime-per-epoch:  564.842224121\n",
      "epoch:  270 \tlatest loss:  0.0547334411624 \tsampled loss:  0.122356894115 \ttime-per-epoch:  563.60244751\n",
      "epoch:  271 \tlatest loss:  0.0818447272738 \tsampled loss:  0.14913592969 \ttime-per-epoch:  557.155609131\n",
      "epoch:  272 \tlatest loss:  0.124869391936 \tsampled loss:  0.200185941563 \ttime-per-epoch:  554.447174072\n",
      "epoch:  273 \tlatest loss:  0.0988429931343 \tsampled loss:  0.161381985544 \ttime-per-epoch:  566.558837891\n",
      "epoch:  274 \tlatest loss:  0.124267378983 \tsampled loss:  0.214453791652 \ttime-per-epoch:  578.718185425\n",
      "epoch:  275 \tlatest loss:  0.0984239083383 \tsampled loss:  0.195701830499 \ttime-per-epoch:  564.880371094\n",
      "epoch:  276 \tlatest loss:  0.105212477871 \tsampled loss:  0.211209766101 \ttime-per-epoch:  566.806793213\n",
      "epoch:  277 \tlatest loss:  0.120421439108 \tsampled loss:  0.216897352679 \ttime-per-epoch:  582.685470581\n",
      "epoch:  278 \tlatest loss:  0.0614205044497 \tsampled loss:  0.184135622211 \ttime-per-epoch:  568.12286377\n",
      "epoch:  279 \tlatest loss:  0.0856100706314 \tsampled loss:  0.190218932851 \ttime-per-epoch:  563.163757324\n",
      "epoch:  280 \tlatest loss:  0.109192968005 \tsampled loss:  0.23793707593 \ttime-per-epoch:  561.723709106\n",
      "epoch:  281 \tlatest loss:  0.0882665562994 \tsampled loss:  0.19933221175 \ttime-per-epoch:  703.525543213\n",
      "epoch:  282 \tlatest loss:  0.114022670014 \tsampled loss:  0.228252428432 \ttime-per-epoch:  563.554763794\n",
      "epoch:  283 \tlatest loss:  0.116643457812 \tsampled loss:  0.213806461475 \ttime-per-epoch:  571.556091309\n",
      "epoch:  284 \tlatest loss:  0.0953725035625 \tsampled loss:  0.199018389719 \ttime-per-epoch:  572.881698608\n",
      "epoch:  285 \tlatest loss:  0.100385684871 \tsampled loss:  0.208901532317 \ttime-per-epoch:  577.955245972\n",
      "epoch:  286 \tlatest loss:  0.0914393488344 \tsampled loss:  0.193902674171 \ttime-per-epoch:  556.955337524\n",
      "epoch:  287 \tlatest loss:  0.0964484339024 \tsampled loss:  0.221292642921 \ttime-per-epoch:  553.722381592\n",
      "epoch:  288 \tlatest loss:  0.0991266311899 \tsampled loss:  0.220571790396 \ttime-per-epoch:  555.91583252\n",
      "epoch:  289 \tlatest loss:  0.104594885504 \tsampled loss:  0.195135272087 \ttime-per-epoch:  562.887191772\n",
      "epoch:  290 \tlatest loss:  0.0836456992377 \tsampled loss:  0.178427722254 \ttime-per-epoch:  568.161010742\n",
      "epoch:  291 \tlatest loss:  0.103340118268 \tsampled loss:  0.225222124729 \ttime-per-epoch:  561.599731445\n",
      "epoch:  292 \tlatest loss:  0.0774224389246 \tsampled loss:  0.160520400738 \ttime-per-epoch:  551.719665527\n",
      "epoch:  293 \tlatest loss:  0.0869825665028 \tsampled loss:  0.182240422321 \ttime-per-epoch:  562.238693237\n",
      "epoch:  294 \tlatest loss:  0.0741788952614 \tsampled loss:  0.204615822793 \ttime-per-epoch:  555.152893066\n",
      "epoch:  295 \tlatest loss:  0.0756307068424 \tsampled loss:  0.159894924261 \ttime-per-epoch:  571.918487549\n",
      "epoch:  296 \tlatest loss:  0.0424881023256 \tsampled loss:  0.130177259185 \ttime-per-epoch:  561.685562134\n",
      "epoch:  297 \tlatest loss:  0.0815074834643 \tsampled loss:  0.185876725082 \ttime-per-epoch:  562.391281128\n",
      "epoch:  298 \tlatest loss:  0.108345484687 \tsampled loss:  0.224427598212 \ttime-per-epoch:  556.602478027\n",
      "epoch:  299 \tlatest loss:  0.107907921513 \tsampled loss:  0.19797874222 \ttime-per-epoch:  550.365447998\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start = time.time()\n",
    "    for batch in range(n_batches):\n",
    "        loss = train(batch,LR)\n",
    "        losses.append((loss[-1],loss[-2]))        \n",
    "    end = time.time()\n",
    "    print \"epoch: \",epoch, \"\\tlatest loss: \",sum([l[0] for l in losses])/len(losses), \"\\tsampled loss: \",sum([l[1] for l in losses])/len(losses),\"\\ttime-per-epoch: \", (end-start)*20000000/N_EDGES\n",
    "    losses = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train batch-by-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch:  0 \tlatest loss:  1.44811612643 \ttime-per-epoch:  4733.01410675\n",
      "loss:  1.44811612643\n",
      "minibatch:  1 \tlatest loss:  1.44447765377 \ttime-per-epoch:  3630.79404831\n",
      "loss:  1.44447765377\n",
      "minibatch:  2 \tlatest loss:  1.44208920334 \ttime-per-epoch:  3696.4302063\n",
      "loss:  1.44208920334\n",
      "minibatch:  3 \tlatest loss:  1.44010470488 \ttime-per-epoch:  3635.37216187\n",
      "loss:  1.44010470488\n",
      "minibatch:  4 \tlatest loss:  1.43848069042 \ttime-per-epoch:  3703.74011993\n",
      "loss:  1.43848069042\n",
      "minibatch:  5 \tlatest loss:  1.43700506824 \ttime-per-epoch:  3633.41808319\n",
      "loss:  1.43700506824\n",
      "minibatch:  6 \tlatest loss:  1.43572430529 \ttime-per-epoch:  3695.1956749\n",
      "loss:  1.43572430529\n",
      "minibatch:  7 \tlatest loss:  1.43455595178 \ttime-per-epoch:  3624.83596802\n",
      "loss:  1.43455595178\n",
      "minibatch:  8 \tlatest loss:  1.43345288669 \ttime-per-epoch:  3696.73395157\n",
      "loss:  1.43345288669\n",
      "minibatch:  9 \tlatest loss:  1.4324084092 \ttime-per-epoch:  3638.83399963\n",
      "loss:  1.4324084092\n",
      "minibatch:  10 \tlatest loss:  1.43151839174 \ttime-per-epoch:  3700.111866\n",
      "loss:  1.43151839174\n",
      "minibatch:  11 \tlatest loss:  1.43068160841 \ttime-per-epoch:  3630.18226624\n",
      "loss:  1.43068160841\n",
      "minibatch:  12 \tlatest loss:  1.42977845547 \ttime-per-epoch:  3694.19002533\n",
      "loss:  1.42977845547\n",
      "minibatch:  13 \tlatest loss:  1.42903739386 \ttime-per-epoch:  3644.69623566\n",
      "loss:  1.42903739386\n",
      "minibatch:  14 \tlatest loss:  1.42819193906 \ttime-per-epoch:  3706.19392395\n",
      "loss:  1.42819193906\n",
      "minibatch:  15 \tlatest loss:  1.42753694972 \ttime-per-epoch:  3643.82982254\n",
      "loss:  1.42753694972\n",
      "minibatch:  16 \tlatest loss:  1.42683044422 \ttime-per-epoch:  3725.55589676\n",
      "loss:  1.42683044422\n",
      "minibatch:  17 \tlatest loss:  1.42614923015 \ttime-per-epoch:  3637.32814789\n",
      "loss:  1.42614923015\n",
      "minibatch:  18 \tlatest loss:  1.42553934188 \ttime-per-epoch:  3705.80387115\n",
      "loss:  1.42553934188\n",
      "minibatch:  19 \tlatest loss:  1.42492557438 \ttime-per-epoch:  3645.83778381\n",
      "loss:  1.42492557438\n",
      "minibatch:  20 \tlatest loss:  1.42434271228 \ttime-per-epoch:  3700.61016083\n",
      "loss:  1.42434271228\n",
      "minibatch:  21 \tlatest loss:  1.42376552894 \ttime-per-epoch:  3632.75003433\n",
      "loss:  1.42376552894\n",
      "minibatch:  22 \tlatest loss:  1.4232230751 \ttime-per-epoch:  3697.94797897\n",
      "loss:  1.4232230751\n",
      "minibatch:  23 \tlatest loss:  1.4226800931 \ttime-per-epoch:  3637.57419586\n",
      "loss:  1.4226800931\n",
      "minibatch:  24 \tlatest loss:  1.42216392006 \ttime-per-epoch:  3697.12781906\n",
      "loss:  1.42216392006\n",
      "minibatch:  25 \tlatest loss:  1.42163967523 \ttime-per-epoch:  3635.44845581\n",
      "loss:  1.42163967523\n",
      "minibatch:  26 \tlatest loss:  1.42120399948 \ttime-per-epoch:  3699.63216782\n",
      "loss:  1.42120399948\n",
      "minibatch:  27 \tlatest loss:  1.42066409265 \ttime-per-epoch:  3633.05616379\n",
      "loss:  1.42066409265\n",
      "minibatch:  28 \tlatest loss:  1.42022302499 \ttime-per-epoch:  3707.36598969\n",
      "loss:  1.42022302499\n",
      "minibatch:  29 \tlatest loss:  1.41977957336 \ttime-per-epoch:  3633.75425339\n",
      "loss:  1.41977957336\n",
      "minibatch:  30 \tlatest loss:  1.41934306488 \ttime-per-epoch:  3701.23767853\n",
      "loss:  1.41934306488\n",
      "minibatch:  31 \tlatest loss:  1.41892381276 \ttime-per-epoch:  3642.96388626\n",
      "loss:  1.41892381276\n",
      "minibatch:  32 \tlatest loss:  1.41852149622 \ttime-per-epoch:  3697.94416428\n",
      "loss:  1.41852149622\n",
      "minibatch:  33 \tlatest loss:  1.41812387477 \ttime-per-epoch:  3633.64171982\n",
      "loss:  1.41812387477\n",
      "minibatch:  34 \tlatest loss:  1.41768668001 \ttime-per-epoch:  3698.80390167\n",
      "loss:  1.41768668001\n",
      "minibatch:  35 \tlatest loss:  1.41730250401 \ttime-per-epoch:  3629.68969345\n",
      "loss:  1.41730250401\n",
      "minibatch:  36 \tlatest loss:  1.41692840137 \ttime-per-epoch:  3714.26200867\n",
      "loss:  1.41692840137\n",
      "minibatch:  37 \tlatest loss:  1.41652501399 \ttime-per-epoch:  3637.92037964\n",
      "loss:  1.41652501399\n",
      "minibatch:  38 \tlatest loss:  1.41615329178 \ttime-per-epoch:  3697.62611389\n",
      "loss:  1.41615329178\n",
      "minibatch:  39 \tlatest loss:  1.41583526723 \ttime-per-epoch:  3633.65983963\n",
      "loss:  1.41583526723\n",
      "minibatch:  40 \tlatest loss:  1.41549047335 \ttime-per-epoch:  3699.32174683\n",
      "loss:  1.41549047335\n",
      "minibatch:  41 \tlatest loss:  1.4151592306 \ttime-per-epoch:  3643.12791824\n",
      "loss:  1.4151592306\n",
      "minibatch:  42 \tlatest loss:  1.41483883807 \ttime-per-epoch:  3706.25972748\n",
      "loss:  1.41483883807\n",
      "minibatch:  43 \tlatest loss:  1.41448858235 \ttime-per-epoch:  3641.54815674\n",
      "loss:  1.41448858235\n",
      "minibatch:  44 \tlatest loss:  1.41416521973 \ttime-per-epoch:  3699.18012619\n",
      "loss:  1.41416521973\n",
      "minibatch:  45 \tlatest loss:  1.41380750885 \ttime-per-epoch:  3639.03427124\n",
      "loss:  1.41380750885\n",
      "minibatch:  46 \tlatest loss:  1.41354296573 \ttime-per-epoch:  3702.93188095\n",
      "loss:  1.41354296573\n",
      "minibatch:  47 \tlatest loss:  1.41326882592 \ttime-per-epoch:  3635.19620895\n",
      "loss:  1.41326882592\n",
      "minibatch:  48 \tlatest loss:  1.41296412245 \ttime-per-epoch:  3704.0719986\n",
      "loss:  1.41296412245\n",
      "minibatch:  49 \tlatest loss:  1.41266868694 \ttime-per-epoch:  3641.55817032\n",
      "loss:  1.41266868694\n",
      "minibatch:  50 \tlatest loss:  1.41233984269 \ttime-per-epoch:  3697.21412659\n",
      "loss:  1.41233984269\n",
      "minibatch:  51 \tlatest loss:  1.41207493182 \ttime-per-epoch:  3647.74608612\n",
      "loss:  1.41207493182\n",
      "minibatch:  52 \tlatest loss:  1.41181291312 \ttime-per-epoch:  3706.3164711\n",
      "loss:  1.41181291312\n",
      "minibatch:  53 \tlatest loss:  1.41153169614 \ttime-per-epoch:  3649.3601799\n",
      "loss:  1.41153169614\n",
      "minibatch:  54 \tlatest loss:  1.41130009704 \ttime-per-epoch:  3706.71415329\n",
      "loss:  1.41130009704\n",
      "minibatch:  55 \tlatest loss:  1.41104639798 \ttime-per-epoch:  3632.32040405\n",
      "loss:  1.41104639798\n",
      "minibatch:  56 \tlatest loss:  1.41079865793 \ttime-per-epoch:  3705.75809479\n",
      "loss:  1.41079865793\n",
      "minibatch:  57 \tlatest loss:  1.41049834262 \ttime-per-epoch:  3637.06207275\n",
      "loss:  1.41049834262\n",
      "minibatch:  58 \tlatest loss:  1.41029534785 \ttime-per-epoch:  3703.79209518\n",
      "loss:  1.41029534785\n",
      "minibatch:  59 \tlatest loss:  1.41003679601 \ttime-per-epoch:  3641.84188843\n",
      "loss:  1.41003679601\n",
      "minibatch:  60 \tlatest loss:  1.40973039713 \ttime-per-epoch:  3706.1920166\n",
      "loss:  1.40973039713\n",
      "minibatch:  61 \tlatest loss:  1.40949792593 \ttime-per-epoch:  3636.02209091\n",
      "loss:  1.40949792593\n",
      "minibatch:  62 \tlatest loss:  1.40933250667 \ttime-per-epoch:  3704.46014404\n",
      "loss:  1.40933250667\n",
      "minibatch:  63 \tlatest loss:  1.40905599726 \ttime-per-epoch:  3636.60383224\n",
      "loss:  1.40905599726\n",
      "minibatch:  64 \tlatest loss:  1.40882420211 \ttime-per-epoch:  3703.64189148\n",
      "loss:  1.40882420211\n",
      "minibatch:  65 \tlatest loss:  1.40860133889 \ttime-per-epoch:  3659.22832489\n",
      "loss:  1.40860133889\n",
      "minibatch:  66 \tlatest loss:  1.40838951207 \ttime-per-epoch:  3701.48992538\n",
      "loss:  1.40838951207\n",
      "minibatch:  67 \tlatest loss:  1.40818719812 \ttime-per-epoch:  3633.99028778\n",
      "loss:  1.40818719812\n",
      "minibatch:  68 \tlatest loss:  1.40800426106 \ttime-per-epoch:  3697.13973999\n",
      "loss:  1.40800426106\n",
      "minibatch:  69 \tlatest loss:  1.40775433743 \ttime-per-epoch:  3733.8180542\n",
      "loss:  1.40775433743\n",
      "minibatch:  70 \tlatest loss:  1.40756507576 \ttime-per-epoch:  3705.50394058\n",
      "loss:  1.40756507576\n",
      "minibatch:  71 \tlatest loss:  1.40732686944 \ttime-per-epoch:  3633.05616379\n",
      "loss:  1.40732686944\n",
      "minibatch:  72 \tlatest loss:  1.40710843088 \ttime-per-epoch:  3714.02215958\n",
      "loss:  1.40710843088\n",
      "minibatch:  73 \tlatest loss:  1.40692807277 \ttime-per-epoch:  3640.24591446\n",
      "loss:  1.40692807277\n",
      "minibatch:  74 \tlatest loss:  1.40669432464 \ttime-per-epoch:  3699.04613495\n",
      "loss:  1.40669432464\n",
      "minibatch:  75 \tlatest loss:  1.40654849837 \ttime-per-epoch:  3643.3339119\n",
      "loss:  1.40654849837\n",
      "minibatch:  76 \tlatest loss:  1.40637333524 \ttime-per-epoch:  3703.79018784\n",
      "loss:  1.40637333524\n",
      "minibatch:  77 \tlatest loss:  1.40617061944 \ttime-per-epoch:  3641.95823669\n",
      "loss:  1.40617061944\n",
      "minibatch:  78 \tlatest loss:  1.40594211828 \ttime-per-epoch:  3706.86197281\n",
      "loss:  1.40594211828\n",
      "minibatch:  79 \tlatest loss:  1.40576812282 \ttime-per-epoch:  3639.0581131\n",
      "loss:  1.40576812282\n",
      "minibatch:  80 \tlatest loss:  1.40560735977 \ttime-per-epoch:  3713.95397186\n",
      "loss:  1.40560735977\n",
      "minibatch:  81 \tlatest loss:  1.40541750671 \ttime-per-epoch:  3659.58595276\n",
      "loss:  1.40541750671\n",
      "minibatch:  82 \tlatest loss:  1.4052684784 \ttime-per-epoch:  4469.77615356\n",
      "loss:  1.4052684784\n",
      "minibatch:  83 \tlatest loss:  1.40503577245 \ttime-per-epoch:  3776.68809891\n",
      "loss:  1.40503577245\n",
      "minibatch:  84 \tlatest loss:  1.40488302282 \ttime-per-epoch:  3706.62403107\n",
      "loss:  1.40488302282\n",
      "minibatch:  85 \tlatest loss:  1.40473684309 \ttime-per-epoch:  3647.2659111\n",
      "loss:  1.40473684309\n",
      "minibatch:  86 \tlatest loss:  1.40456670211 \ttime-per-epoch:  3704.5879364\n",
      "loss:  1.40456670211\n",
      "minibatch:  87 \tlatest loss:  1.40439623742 \ttime-per-epoch:  3640.48624039\n",
      "loss:  1.40439623742\n",
      "minibatch:  88 \tlatest loss:  1.40421847939 \ttime-per-epoch:  3717.21220016\n",
      "loss:  1.40421847939\n",
      "minibatch:  89 \tlatest loss:  1.40403993971 \ttime-per-epoch:  3660.2139473\n",
      "loss:  1.40403993971\n",
      "minibatch:  90 \tlatest loss:  1.40391918877 \ttime-per-epoch:  3734.42792892\n",
      "loss:  1.40391918877\n",
      "minibatch:  91 \tlatest loss:  1.40373523135 \ttime-per-epoch:  3643.93186569\n",
      "loss:  1.40373523135\n",
      "minibatch:  92 \tlatest loss:  1.40360643475 \ttime-per-epoch:  3713.39797974\n",
      "loss:  1.40360643475\n",
      "minibatch:  93 \tlatest loss:  1.40343427486 \ttime-per-epoch:  4081.82382584\n",
      "loss:  1.40343427486\n",
      "minibatch:  94 \tlatest loss:  1.40325966346 \ttime-per-epoch:  4710.98566055\n",
      "loss:  1.40325966346\n",
      "minibatch:  95 \tlatest loss:  1.40314013819 \ttime-per-epoch:  4628.50570679\n",
      "loss:  1.40314013819\n",
      "minibatch:  96 \tlatest loss:  1.40296611881 \ttime-per-epoch:  4678.92599106\n",
      "loss:  1.40296611881\n",
      "minibatch:  97 \tlatest loss:  1.40281907582 \ttime-per-epoch:  4628.00598145\n",
      "loss:  1.40281907582\n",
      "minibatch:  98 \tlatest loss:  1.4026686218 \ttime-per-epoch:  4680.47189713\n",
      "loss:  1.4026686218\n",
      "minibatch:  99 \tlatest loss:  1.40256758749 \ttime-per-epoch:  4634.06801224\n",
      "loss:  1.40256758749\n",
      "minibatch:  100 \tlatest loss:  1.40236894811 \ttime-per-epoch:  4256.68811798\n",
      "loss:  1.40236894811\n",
      "minibatch:  101 \tlatest loss:  1.40222442573 \ttime-per-epoch:  3631.41012192\n",
      "loss:  1.40222442573\n",
      "minibatch:  102 \tlatest loss:  1.40210795601 \ttime-per-epoch:  3689.76831436\n",
      "loss:  1.40210795601\n",
      "minibatch:  103 \tlatest loss:  1.40196419153 \ttime-per-epoch:  3628.89623642\n",
      "loss:  1.40196419153\n",
      "minibatch:  104 \tlatest loss:  1.40186906903 \ttime-per-epoch:  3689.1617775\n",
      "loss:  1.40186906903\n",
      "minibatch:  105 \tlatest loss:  1.4016571981 \ttime-per-epoch:  3636.6276741\n",
      "loss:  1.4016571981\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-369-5f10797ce34f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for batch in range(n_batches):\n",
    "        start = time.time()\n",
    "        loss = train(batch,1)[-1]\n",
    "        end = time.time()\n",
    "        print \"minibatch: \",epoch*n_batches+batch,\"\\tlatest loss: \",loss, \"\\ttime-per-epoch: \", (end-start)*20000000*n_batches/N_EDGES\n",
    "        print \"loss: \",loss    \n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate with sampling"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
